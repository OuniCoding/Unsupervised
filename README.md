åœ¨å½±åƒä¸Šä½¿ç”¨ **éç›£ç£å¼å­¸ç¿’ (Unsupervised Learning)** ä¾†åµæ¸¬ **ç•°å¸¸ä½ç½®**ï¼Œå¸¸è¦‹çš„æ–¹æ³•åŒ…æ‹¬ï¼š  

1. **è‡ªç·¨ç¢¼å™¨ (Autoencoder, AE)**
2. **è®Šåˆ†è‡ªç·¨ç¢¼å™¨ (Variational Autoencoder, VAE)**
3. **ç”Ÿæˆå°æŠ—ç¶²è·¯ (Generative Adversarial Network, GAN)**
4. **å±€éƒ¨ç•°å¸¸å› å­ (Local Outlier Factor, LOF)**
5. **ä¸»æˆåˆ†åˆ†æ (PCA)**
6. **æ·±åº¦ç‰¹å¾µå­¸ç¿’ + å¯†åº¦ä¼°è¨ˆ (Deep Feature Extraction + Density Estimation)**

é€™äº›æ–¹æ³•å¤§å¤šæ•¸æ˜¯åŸºæ–¼ **å­¸ç¿’æ­£å¸¸æ¨£æœ¬çš„åˆ†ä½ˆ**ï¼Œç„¶å¾Œåœ¨æ¸¬è©¦éšæ®µæª¢æ¸¬èˆ‡æ­£å¸¸æ¨£æœ¬å·®ç•°è¼ƒå¤§çš„å€åŸŸï¼Œä½œç‚ºç•°å¸¸é»ã€‚

---

## **1. è‡ªç·¨ç¢¼å™¨ (Autoencoder, AE)**
### **æ¦‚å¿µ**
- è¨“ç·´æ¨¡å‹å­¸ç¿’ **æ­£å¸¸å½±åƒçš„ç‰¹å¾µå£“ç¸®èˆ‡é‚„åŸ**ã€‚
- ç•¶æ¸¬è©¦åœ–åƒèˆ‡æ­£å¸¸å½±åƒæœ‰è¼ƒå¤§å·®ç•°æ™‚ï¼Œé‡å»ºèª¤å·®æœƒè¼ƒå¤§ï¼Œé€²è€Œæ¨™è¨˜ç•°å¸¸å€åŸŸã€‚

### **æ­¥é©Ÿ**
1. è¨“ç·´ **Autoencoder** åƒ…ä½¿ç”¨ **æ­£å¸¸æ¨£æœ¬**ã€‚
2. åœ¨æ¸¬è©¦å½±åƒä¸­è¨ˆç®—è¼¸å…¥å½±åƒèˆ‡é‡å»ºå½±åƒçš„ **åƒç´ èª¤å·® (MSE)**ã€‚
3. ä½¿ç”¨ç†±åœ– (heatmap) æ¨™ç¤ºç•°å¸¸å€åŸŸã€‚

### **Python ç¨‹å¼**
```python
import numpy as np
import cv2
import tensorflow as tf
from tensorflow.keras.models import Model
from tensorflow.keras.layers import Input, Conv2D, UpSampling2D
import matplotlib.pyplot as plt

# å»ºç«‹è‡ªç·¨ç¢¼å™¨
input_img = Input(shape=(128, 128, 1))
x = Conv2D(32, (3, 3), activation='relu', padding='same')(input_img)
x = Conv2D(16, (3, 3), activation='relu', padding='same')(x)
encoded = Conv2D(8, (3, 3), activation='relu', padding='same')(x)

x = Conv2D(16, (3, 3), activation='relu', padding='same')(encoded)
x = Conv2D(32, (3, 3), activation='relu', padding='same')(x)
decoded = Conv2D(1, (3, 3), activation='sigmoid', padding='same')(x)

autoencoder = Model(input_img, decoded)
autoencoder.compile(optimizer='adam', loss='mse')

# è¨“ç·´è‡ªç·¨ç¢¼å™¨
train_images = np.random.rand(1000, 128, 128, 1)  # å‡è¨­æœ‰1000å¼µæ­£å¸¸å½±åƒ
autoencoder.fit(train_images, train_images, epochs=50, batch_size=16)

# æ¸¬è©¦å½±åƒ (ç•°å¸¸å½±åƒ)
test_image = np.random.rand(128, 128, 1)  # å‡è¨­æœ‰ä¸€å¼µç•°å¸¸å½±åƒ
reconstructed = autoencoder.predict(test_image[np.newaxis, ...])[0]

# è¨ˆç®—ç•°å¸¸åˆ†ä½ˆ (èª¤å·®åœ–)
error_map = np.abs(test_image - reconstructed)

# é¡¯ç¤ºç•°å¸¸ç†±åœ–
plt.imshow(error_map, cmap='hot')
plt.colorbar()
plt.show()
```

---

## **2. è®Šåˆ†è‡ªç·¨ç¢¼å™¨ (Variational Autoencoder, VAE)**
VAE æ˜¯ Autoencoder çš„é€²éšç‰ˆï¼Œèƒ½å¤ å­¸ç¿’ **æ›´å…·ä¸€èˆ¬æ€§çš„ç‰¹å¾µåˆ†ä½ˆ**ï¼Œå°ç•°å¸¸æª¢æ¸¬æ›´ç©©å¥ã€‚

---

## **3. ç”Ÿæˆå°æŠ—ç¶²è·¯ (GAN)**
### **æ¦‚å¿µ**
- è¨“ç·´ **GAN ç”Ÿæˆæ­£å¸¸æ¨£æœ¬**ï¼Œä¸¦åœ¨æ¸¬è©¦æ™‚è®“ **ç•°å¸¸æ¨£æœ¬** é€šé GANï¼Œè¨ˆç®—ç•°å¸¸å€åŸŸã€‚
- **CycleGAN** ä¹Ÿå¯ä»¥ç”¨ä¾†åšç•°å¸¸åµæ¸¬ã€‚

---

## **4. å±€éƒ¨ç•°å¸¸å› å­ (Local Outlier Factor, LOF)**
å¦‚æœä¸æƒ³ä½¿ç”¨æ·±åº¦å­¸ç¿’ï¼Œå¯ä»¥å˜—è©¦ **LOF**ï¼Œåˆ©ç”¨ **é„°è¿‘æ¨£æœ¬å¯†åº¦ä¾†åµæ¸¬ç•°å¸¸é»**ã€‚

```python
from sklearn.neighbors import LocalOutlierFactor
import numpy as np

# è¨“ç·´æ­£å¸¸æ¨£æœ¬
X_train = np.random.rand(100, 2)  # 100å¼µæ­£å¸¸å½±åƒç‰¹å¾µ
X_test = np.random.rand(10, 2)    # 10å¼µæ¸¬è©¦å½±åƒç‰¹å¾µ

lof = LocalOutlierFactor(n_neighbors=20)
y_pred = lof.fit_predict(X_test)

print(y_pred)  # -1 ä»£è¡¨ç•°å¸¸æ¨£æœ¬
```

---

## **5. ä¸»æˆåˆ†åˆ†æ (PCA)**
PCA å¯ä»¥ç”¨ä¾†é™ç¶­ï¼Œä¸¦æ‰¾å‡ºç•°å¸¸çš„å½±åƒç‰¹å¾µã€‚

```python
from sklearn.decomposition import PCA

pca = PCA(n_components=10)
pca.fit(X_train)
X_test_pca = pca.transform(X_test)
```

---

## **6. æ·±åº¦ç‰¹å¾µå­¸ç¿’ + å¯†åº¦ä¼°è¨ˆ**
é€™ç¨®æ–¹æ³•é©åˆ **å°æ¨£æœ¬ç•°å¸¸åµæ¸¬**ï¼Œå¯ä»¥ä½¿ç”¨ **é è¨“ç·´æ¨¡å‹ (å¦‚ ResNetã€VGG)** ä¾†æå–å½±åƒç‰¹å¾µï¼Œç„¶å¾Œç”¨ **é«˜æ–¯æ··åˆæ¨¡å‹ (GMM) æˆ– KDE** ä¾†ä¼°è¨ˆç•°å¸¸é»ã€‚

```python
from tensorflow.keras.applications import VGG16
from sklearn.mixture import GaussianMixture

# åŠ è¼‰é è¨“ç·´æ¨¡å‹
model = VGG16(weights='imagenet', include_top=False)

# æå–æ­£å¸¸æ¨£æœ¬ç‰¹å¾µ
X_train_features = model.predict(X_train)
X_test_features = model.predict(X_test)

# è¨“ç·´ GMM æ¨¡å‹
gmm = GaussianMixture(n_components=2)
gmm.fit(X_train_features)

# é æ¸¬ç•°å¸¸åˆ†æ•¸
scores = gmm.score_samples(X_test_features)
```

---

## **ç¸½çµ**
| æ–¹æ³• | å„ªé» | ç¼ºé» |
|------|------|------|
| **Autoencoder (AE)** | è¨“ç·´ç°¡å–®ï¼Œé©åˆå½±åƒç•°å¸¸åµæ¸¬ | å¯èƒ½ç„¡æ³•æ•æ‰å°å‹ç•°å¸¸ |
| **VAE** | å­¸ç¿’æ›´ä¸€èˆ¬åŒ–çš„ç‰¹å¾µ | è¨ˆç®—é‡è¼ƒå¤§ |
| **GAN** | å¯ç”Ÿæˆé€¼çœŸçš„æ­£å¸¸æ¨£æœ¬ | è¨“ç·´ä¸ç©©å®š |
| **LOF** | é©åˆå°æ•¸æ“š | å—ç‰¹å¾µé¸æ“‡å½±éŸ¿å¤§ |
| **PCA** | è¨ˆç®—é‡å°ï¼Œæ˜“è§£é‡‹ | ç„¡æ³•è™•ç†é«˜ç¶­è¤‡é›œæ•¸æ“š |
| **æ·±åº¦ç‰¹å¾µ + KDE/GMM** | å¯è™•ç†å°æ¨£æœ¬ç•°å¸¸æª¢æ¸¬ | ä¾è³´é è¨“ç·´æ¨¡å‹ |

ğŸ‘‰ **æ¨è–¦ï¼š**
- è‹¥æœ‰ GPUï¼Œä½¿ç”¨ **Autoencoder æˆ– VAE**ã€‚
- è‹¥æ¨£æœ¬æ¥µå°‘ï¼Œå¯ç”¨ **æ·±åº¦ç‰¹å¾µ + KDE**ã€‚
- è‹¥ä¸æƒ³ç”¨æ·±åº¦å­¸ç¿’ï¼Œå¯è©¦è©¦ **LOF æˆ– PCA**ã€‚

---

å¦‚æœä½ çš„æ¨£æœ¬**æ¥µå°‘**ï¼Œå»ºè­°ä½¿ç”¨ **é·ç§»å­¸ç¿’ + éç›£ç£ç•°å¸¸åµæ¸¬** æˆ– **One-Class SVM/Isolation Forest**ã€‚é€™äº›æ–¹æ³•ä¸éœ€è¦å¤§é‡æ¨™è¨»æ•¸æ“šï¼Œé©åˆå°æ¨£æœ¬å ´æ™¯ã€‚ä»¥ä¸‹æ˜¯è©³ç´°å»ºè­°å’Œç¨‹å¼ç¯„ä¾‹ï¼š

---

## **æ–¹æ³• 1ï¼šé·ç§»å­¸ç¿’ + éç›£ç£ç•°å¸¸åµæ¸¬ (GMM/LOF/KDE)**
### **æ¦‚å¿µ**
1. **ä½¿ç”¨é è¨“ç·´ CNN æ¨¡å‹** (å¦‚ VGG16ã€ResNet) æå–å½±åƒç‰¹å¾µã€‚
2. **ä½¿ç”¨çµ±è¨ˆæ–¹æ³•** (å¦‚ **Gaussian Mixture Model (GMM)** æˆ– **å±€éƒ¨ç•°å¸¸å› å­ (LOF)**) ä¾†æª¢æ¸¬ç•°å¸¸ã€‚
3. **ç„¡éœ€å¤§é‡è¨“ç·´æ•¸æ“š**ï¼Œåªéœ€è¦**å¹¾å¼µæ­£å¸¸æ¨£æœ¬**ã€‚

### **ç¨‹å¼**
```python
import numpy as np
import tensorflow as tf
from tensorflow.keras.applications import VGG16
from sklearn.mixture import GaussianMixture  # GMM
from sklearn.neighbors import LocalOutlierFactor  # LOF

# è¼‰å…¥ VGG16 é è¨“ç·´æ¨¡å‹ (ä¸åŒ…å«å…¨é€£æ¥å±¤)
base_model = VGG16(weights='imagenet', include_top=False, input_shape=(224, 224, 3))

# æå–å½±åƒç‰¹å¾µ
def extract_features(image):
    image = tf.image.resize(image, (224, 224)) / 255.0  # è½‰æ›å°ºå¯¸ä¸¦æ­£è¦åŒ–
    features = base_model.predict(np.expand_dims(image, axis=0))
    return features.flatten()

# **1. è¨“ç·´éšæ®µ**
# å‡è¨­æœ‰ 5 å¼µæ­£å¸¸æ¨£æœ¬
normal_images = np.random.rand(5, 224, 224, 3)  # é€™è£¡ç”¨éš¨æ©Ÿå½±åƒæ¨¡æ“¬
X_train_features = np.array([extract_features(img) for img in normal_images])

# è¨“ç·´ç•°å¸¸åµæ¸¬æ¨¡å‹ (é¸æ“‡ GMM æˆ– LOF)
gmm = GaussianMixture(n_components=1, covariance_type="full").fit(X_train_features)
lof = LocalOutlierFactor(n_neighbors=2).fit(X_train_features)

# **2. æ¸¬è©¦éšæ®µ**
test_image = np.random.rand(224, 224, 3)  # æ¨¡æ“¬ç•°å¸¸å½±åƒ
test_feature = extract_features(test_image)

# **ä½¿ç”¨ GMM åˆ¤æ–·ç•°å¸¸**
score = gmm.score_samples([test_feature])
threshold = np.percentile(gmm.score_samples(X_train_features), 5)  # è¨­å®šç•°å¸¸é–¾å€¼
if score < threshold:
    print("ç•°å¸¸å½±åƒï¼")
else:
    print("æ­£å¸¸å½±åƒ")

# **ä½¿ç”¨ LOF åˆ¤æ–·ç•°å¸¸**
if lof.predict([test_feature])[0] == -1:
    print("ç•°å¸¸å½±åƒï¼(LOF)")
else:
    print("æ­£å¸¸å½±åƒ (LOF)")
```
### **ç‚ºä»€éº¼é©åˆå°æ¨£æœ¬ï¼Ÿ**
âœ… ç„¡éœ€å¤§é‡è¨“ç·´  
âœ… ä½¿ç”¨ **é è¨“ç·´æ¨¡å‹**ï¼Œåƒ…æå–å½±åƒç‰¹å¾µ  
âœ… **GMM/LOF** ä¸éœ€è¦æ¨™è¨»ç•°å¸¸æ¨£æœ¬  

---

## **æ–¹æ³• 2ï¼šOne-Class SVM (OC-SVM)**
å¦‚æœåªæœ‰**æ­£å¸¸å½±åƒ**ï¼Œå¯ä»¥ç”¨ **One-Class SVM** è¨“ç·´æ¨¡å‹ä¾†å­¸ç¿’æ­£å¸¸æ¨£æœ¬åˆ†ä½ˆï¼Œç„¶å¾Œæª¢æ¸¬ç•°å¸¸æ¨£æœ¬ã€‚

### **ç¨‹å¼**
```python
from sklearn.svm import OneClassSVM

# è¨“ç·´ One-Class SVM
oc_svm = OneClassSVM(kernel='rbf', gamma='scale').fit(X_train_features)

# æ¸¬è©¦å½±åƒ
if oc_svm.predict([test_feature])[0] == -1:
    print("ç•°å¸¸å½±åƒï¼")
else:
    print("æ­£å¸¸å½±åƒ")
```
### **å„ªå‹¢**
âœ… é©åˆ **æ¥µå°‘æ¨£æœ¬ (5~10 å¼µ)**  
âœ… **ç„¡éœ€ç•°å¸¸æ¨£æœ¬**  
âœ… è¨ˆç®—é€Ÿåº¦å¿«  

---

## **æ–¹æ³• 3ï¼šFew-Shot Learning (Siamese Network)**
å¦‚æœä½ æœ‰å°‘é‡ç•°å¸¸æ¨£æœ¬ (ä¾‹å¦‚ 5~10 å¼µ)ï¼Œå¯ä»¥ä½¿ç”¨ **Siamese Network** ä¾†æ¯”è¼ƒå½±åƒç›¸ä¼¼åº¦ã€‚

### **æ¦‚å¿µ**
- è¨“ç·´ä¸€å€‹ **Siamese Network** ä¾†å­¸ç¿’å½±åƒä¹‹é–“çš„è·é›¢ã€‚
- å¦‚æœæ–°å½±åƒèˆ‡æ­£å¸¸æ¨£æœ¬çš„è·é›¢éå¤§ï¼Œå‰‡è¦–ç‚ºç•°å¸¸ã€‚

é€™ç¨®æ–¹æ³•é©åˆ **å°‘é‡ç•°å¸¸æ¨£æœ¬ï¼Œä½†ä»éœ€ä¸€äº›æ¨™è¨»æ•¸æ“š**ã€‚

---

## **æ–¹æ³• 4ï¼šåˆæˆæ•¸æ“š (Data Augmentation)**
å¦‚æœåªæœ‰å°‘æ•¸æ­£å¸¸æ¨£æœ¬ï¼Œå¯ä»¥é€éæ•¸æ“šå¢å¼·ä¾†æ“´å±•æ•¸æ“šé‡ï¼Œç„¶å¾Œå†é€²è¡Œç•°å¸¸åµæ¸¬ã€‚

### **æ•¸æ“šå¢å¼·ç¯„ä¾‹**
```python
from tensorflow.keras.preprocessing.image import ImageDataGenerator

datagen = ImageDataGenerator(rotation_range=20, width_shift_range=0.2, height_shift_range=0.2, horizontal_flip=True)

augmented_images = []
for img in normal_images:
    img = np.expand_dims(img, axis=0)
    for _ in range(5):  # ç”Ÿæˆ 5 å€‹æ“´å±•å½±åƒ
        augmented_images.append(datagen.flow(img, batch_size=1)[0][0])
```
âœ… é©åˆ **æ¥µå°‘æ¨£æœ¬ä½†å¯ä»¥æ“´å±•æ•¸æ“š**  
âœ… é€éæ—‹è½‰ã€ç¿»è½‰ã€é¡è‰²è®ŠåŒ–ä¾† **å¢åŠ æ•¸æ“šé‡**  

---

## **ç¸½çµ**
| æ–¹æ³• | é©ç”¨æƒ…å¢ƒ | éœ€è¦ç•°å¸¸æ¨£æœ¬ï¼Ÿ | é©åˆæ¨£æœ¬æ•¸é‡ |
|------|--------|--------------|------------|
| **é·ç§»å­¸ç¿’ + GMM/LOF/KDE** | ç„¡éœ€å¤§é‡è¨“ç·´ï¼Œé©åˆå°æ¨£æœ¬ | âŒ ä¸éœ€è¦ | 5~10 |
| **One-Class SVM (OC-SVM)** | åªæœ‰æ­£å¸¸å½±åƒ | âŒ ä¸éœ€è¦ | 5~10 |
| **Few-Shot Learning (Siamese Network)** | å°‘é‡ç•°å¸¸æ¨£æœ¬ | âœ… éœ€è¦ | 5~10 |
| **Data Augmentation** | é€éæ•¸æ“šå¢å¼·æ“´å±•æ¨£æœ¬ | âŒ ä¸éœ€è¦ | 5~10 |

### **æœ€ä½³é¸æ“‡**
1ï¸âƒ£ **å¦‚æœä½ åªæœ‰** `5~10` **å¼µæ­£å¸¸æ¨£æœ¬** â†’ **é·ç§»å­¸ç¿’ + GMM/LOF/OC-SVM**  
2ï¸âƒ£ **å¦‚æœä½ æœ‰** `5~10` **å¼µç•°å¸¸æ¨£æœ¬** â†’ **Few-Shot Learning**  
3ï¸âƒ£ **å¦‚æœä½ èƒ½ç”¢ç”Ÿæ›´å¤šæ¨£æœ¬** â†’ **Data Augmentation**  

---

### **ä½ çš„æ‡‰ç”¨å ´æ™¯æ˜¯ï¼Ÿ**
ğŸ“Œ **ä½ æ˜¯åªæœ‰æ­£å¸¸å½±åƒï¼Œé‚„æ˜¯æœ‰å°‘æ•¸ç•°å¸¸å½±åƒå‘¢ï¼Ÿ**  
ğŸ“Œ **æ˜¯å¦å¯ä»¥é¡å¤–æ‹æ”å¹¾å¼µç…§ç‰‡ä¾†å¢åŠ æ¨£æœ¬ï¼Ÿ**  
ğŸ“Œ **ä½ çš„å½±åƒè³‡æ–™ä¾†è‡ªå“ªç¨®æ‡‰ç”¨ (ç”¢å“ç‘•ç–µã€é†«å­¸å½±åƒã€å·¥æ¥­æª¢æ¸¬)ï¼Ÿ**  

---

### **æ–¹æ³• 1ï¼šé·ç§»å­¸ç¿’ + éç›£ç£ç•°å¸¸åµæ¸¬ (GMM/LOF/KDE) çš„è¨“ç·´æ•¸æ“šæº–å‚™**
å› ç‚ºä½ åªæœ‰**æ¥µå°‘æ¨£æœ¬**ï¼Œæ‰€ä»¥æˆ‘å€‘çš„ç›®æ¨™æ˜¯ï¼š
1. **æ”¶é›† & æ“´å±•æ­£å¸¸å½±åƒ**ï¼ˆ5~10 å¼µæ­£å¸¸æ¨£æœ¬ï¼‰
2. **æå–ç‰¹å¾µ**ï¼ˆä½¿ç”¨é è¨“ç·´ CNNï¼Œå¦‚ VGG16ï¼‰
3. **è¨“ç·´ç•°å¸¸åµæ¸¬æ¨¡å‹**ï¼ˆGMMã€LOFã€OC-SVMï¼‰

---

## **ğŸ”¹ æ­¥é©Ÿ 1ï¼šæ”¶é›†æ­£å¸¸æ¨£æœ¬**
- æ”¶é›† **è‡³å°‘ 5~10 å¼µ** æ­£å¸¸ç”¢å“å½±åƒ
- ç¢ºä¿å½±åƒæ ¼å¼ä¸€è‡´ï¼ˆå¦‚ `.jpg` æˆ– `.png`ï¼‰
- å»ºç«‹å½±åƒè³‡æ–™å¤¾çµæ§‹ï¼š
  ```
  dataset/
  â”œâ”€â”€ normal/  # æ­£å¸¸æ¨£æœ¬
  â”‚   â”œâ”€â”€ img1.jpg
  â”‚   â”œâ”€â”€ img2.jpg
  â”‚   â”œâ”€â”€ img3.jpg
  â”‚   â”œâ”€â”€ ...
  ```

---

## **ğŸ”¹ æ­¥é©Ÿ 2ï¼šæ•¸æ“šæ“´å¢ï¼ˆData Augmentationï¼Œé¸æ“‡æ€§ï¼‰**
**å¦‚æœæ•¸æ“šæ¥µå°‘**ï¼Œå¯ä»¥ä½¿ç”¨æ•¸æ“šæ“´å¢ä¾†å¢åŠ æ¨£æœ¬æ•¸é‡ï¼š
```python
from tensorflow.keras.preprocessing.image import ImageDataGenerator
import numpy as np
import cv2
import os

datagen = ImageDataGenerator(rotation_range=20, width_shift_range=0.2, height_shift_range=0.2, horizontal_flip=True)

def augment_images(input_folder, output_folder, augment_count=5):
    os.makedirs(output_folder, exist_ok=True)
    for img_name in os.listdir(input_folder):
        img_path = os.path.join(input_folder, img_name)
        img = cv2.imread(img_path)
        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)
        img = np.expand_dims(img, axis=0)

        # ç”¢ç”Ÿæ–°çš„å½±åƒ
        i = 0
        for batch in datagen.flow(img, batch_size=1):
            new_img_path = os.path.join(output_folder, f"aug_{i}_{img_name}")
            cv2.imwrite(new_img_path, cv2.cvtColor(batch[0].astype('uint8'), cv2.COLOR_RGB2BGR))
            i += 1
            if i >= augment_count:
                break

# é€²è¡Œæ•¸æ“šå¢å¼·
augment_images("dataset/normal", "dataset/augmented_normal")
```
- **ä½œç”¨**ï¼šé€é **æ—‹è½‰ã€å¹³ç§»ã€ç¿»è½‰** æ“´å¢æ•¸æ“š
- **çµæœ**ï¼š5 å¼µ â†’ 25~50 å¼µ

---

## **ğŸ”¹ æ­¥é©Ÿ 3ï¼šæå–å½±åƒç‰¹å¾µ**
- ä½¿ç”¨ **VGG16** æˆ– **ResNet50** é è¨“ç·´æ¨¡å‹ä¾†æå–å½±åƒç‰¹å¾µ
- æ¯å¼µå½±åƒæœƒè½‰æ›æˆä¸€å€‹**ç‰¹å¾µå‘é‡**
  
```python
import numpy as np
import tensorflow as tf
from tensorflow.keras.applications import VGG16
from tensorflow.keras.applications.vgg16 import preprocess_input
import cv2
import os

# è¼‰å…¥ VGG16 é è¨“ç·´æ¨¡å‹ (å»æ‰æœ€å¾Œåˆ†é¡å±¤)
base_model = VGG16(weights='imagenet', include_top=False, input_shape=(224, 224, 3))

# å½±åƒè½‰æ›å‡½æ•¸
def extract_features(img_path):
    img = cv2.imread(img_path)
    img = cv2.resize(img, (224, 224))
    img = preprocess_input(img)  # æ­£è¦åŒ–
    img = np.expand_dims(img, axis=0)

    # ä½¿ç”¨ CNN æå–ç‰¹å¾µ
    features = base_model.predict(img)
    return features.flatten()

# è®€å–æ‰€æœ‰æ­£å¸¸å½±åƒ
image_folder = "dataset/augmented_normal"
X_train = []
for img_name in os.listdir(image_folder):
    img_path = os.path.join(image_folder, img_name)
    X_train.append(extract_features(img_path))

X_train = np.array(X_train)  # è½‰ç‚º NumPy é™£åˆ—
np.save("normal_features.npy", X_train)  # ä¿å­˜ç‰¹å¾µ
```
- **ä½œç”¨**ï¼šå°‡å½±åƒè½‰æ›æˆç‰¹å¾µå‘é‡  
- **çµæœ**ï¼šæ¯å¼µå½±åƒ â†’ ä¸€å€‹ `1x4096` çš„ç‰¹å¾µå‘é‡  

---

## **ğŸ”¹ æ­¥é©Ÿ 4ï¼šè¨“ç·´ç•°å¸¸åµæ¸¬æ¨¡å‹**
é€™è£¡æˆ‘å€‘æä¾›ä¸‰ç¨®æ–¹æ³•ï¼ˆGMMã€LOFã€OC-SVMï¼‰ï¼Œå¯é¸æ“‡æœ€é©åˆçš„ã€‚

### **(1) ä½¿ç”¨ Gaussian Mixture Model (GMM)**
```python
from sklearn.mixture import GaussianMixture

X_train = np.load("normal_features.npy")  # è¼‰å…¥ç‰¹å¾µæ•¸æ“š

# è¨“ç·´ GMM æ¨¡å‹
gmm = GaussianMixture(n_components=1, covariance_type="full")
gmm.fit(X_train)

# å„²å­˜æ¨¡å‹
import joblib
joblib.dump(gmm, "gmm_model.pkl")
```
ğŸ“Œ **ä½œç”¨**ï¼šå­¸ç¿’æ­£å¸¸æ¨£æœ¬çš„åˆ†ä½ˆï¼Œè¨ˆç®—ç•°å¸¸æ¨£æœ¬çš„å¯èƒ½æ€§  
ğŸ“Œ **åˆ¤æ–·ç•°å¸¸**ï¼šå¦‚æœ **score** ä½æ–¼é–¾å€¼ï¼Œå‰‡è¦–ç‚ºç•°å¸¸  

---

### **(2) ä½¿ç”¨ Local Outlier Factor (LOF)**
```python
from sklearn.neighbors import LocalOutlierFactor

X_train = np.load("normal_features.npy")

# è¨“ç·´ LOF æ¨¡å‹
lof = LocalOutlierFactor(n_neighbors=5, novelty=True)
lof.fit(X_train)

# å„²å­˜æ¨¡å‹
joblib.dump(lof, "lof_model.pkl")
```
ğŸ“Œ **ä½œç”¨**ï¼šæ¯”è¼ƒæ¨£æœ¬èˆ‡æœ€è¿‘é„°çš„è·é›¢ä¾†åˆ¤æ–·æ˜¯å¦ç•°å¸¸  
ğŸ“Œ **é©åˆå°æ¨£æœ¬**ï¼Œå¯ç”¨æ–¼å³æ™‚æª¢æ¸¬  

---

### **(3) ä½¿ç”¨ One-Class SVM (OC-SVM)**
```python
from sklearn.svm import OneClassSVM

X_train = np.load("normal_features.npy")

# è¨“ç·´ OC-SVM
oc_svm = OneClassSVM(kernel='rbf', gamma='scale')
oc_svm.fit(X_train)

# å„²å­˜æ¨¡å‹
joblib.dump(oc_svm, "oc_svm_model.pkl")
```
ğŸ“Œ **ä½œç”¨**ï¼šå­¸ç¿’æ­£å¸¸æ¨£æœ¬çš„é‚Šç•Œï¼Œè¶…å‡ºç¯„åœå³ç‚ºç•°å¸¸  
ğŸ“Œ **é©åˆæ¥µå°‘æ¨£æœ¬**ï¼Œä½†å¯èƒ½å°é›œè¨Šæ•æ„Ÿ  

---

## **ğŸ”¹ æ­¥é©Ÿ 5ï¼šæ¸¬è©¦æ–°å½±åƒ**
å‡è¨­æœ‰ä¸€å¼µæ–°å½±åƒ `test.jpg`ï¼Œæˆ‘å€‘éœ€è¦åˆ¤æ–·å®ƒæ˜¯å¦ç‚ºç•°å¸¸æ¨£æœ¬ã€‚

```python
import joblib

# è®€å–æ¸¬è©¦å½±åƒç‰¹å¾µ
test_image_path = "test.jpg"
test_feature = extract_features(test_image_path)

# è¼‰å…¥ GMM æ¨¡å‹
gmm = joblib.load("gmm_model.pkl")

# åˆ¤æ–·ç•°å¸¸
score = gmm.score_samples([test_feature])  # è¨ˆç®—æ©Ÿç‡åˆ†æ•¸
threshold = np.percentile(gmm.score_samples(X_train), 5)  # 5% ç•°å¸¸é–¾å€¼

if score < threshold:
    print("âš ï¸ ç•°å¸¸å½±åƒ")
else:
    print("âœ… æ­£å¸¸å½±åƒ")
```
ğŸ“Œ **åˆ†æ•¸è¼ƒä½ â†’ è¦–ç‚ºç•°å¸¸**  
ğŸ“Œ **GMMã€LOFã€OC-SVM çš„ç•°å¸¸æª¢æ¸¬æ–¹å¼é¡ä¼¼**ï¼Œå¯æ ¹æ“šéœ€è¦æ›¿æ›æ¨¡å‹  

---

## **ğŸ“Œ ç¸½çµ**
1ï¸âƒ£ **æ”¶é›†å°‘é‡æ­£å¸¸æ¨£æœ¬** (5~10 å¼µ)  
2ï¸âƒ£ **æ•¸æ“šæ“´å¢ (Data Augmentation)**ï¼ˆæ“´å±•è‡³ 25+ å¼µï¼‰  
3ï¸âƒ£ **ä½¿ç”¨ VGG16 æå–å½±åƒç‰¹å¾µ**ï¼ˆè½‰æ›ç‚º 4096 ç¶­å‘é‡ï¼‰  
4ï¸âƒ£ **è¨“ç·´ GMM/LOF/OC-SVM æ¨¡å‹**ï¼ˆå­¸ç¿’æ­£å¸¸æ¨£æœ¬åˆ†ä½ˆï¼‰  
5ï¸âƒ£ **æ¸¬è©¦æ–°å½±åƒï¼Œåˆ¤æ–·æ˜¯å¦ç‚ºç•°å¸¸** ğŸš€  

ğŸ“Œ **é€™ç¨®æ–¹æ³•ç‰¹åˆ¥é©åˆç‘•ç–µæª¢æ¸¬ã€ç¼ºé™·åˆ†é¡ç­‰æ¥µå°‘æ¨£æœ¬æ‡‰ç”¨ï¼**  

---

åœ¨æª¢æ¸¬ç»ç’ƒç“¶è£‚ç—•çš„æƒ…å¢ƒä¸‹ï¼Œ**æœ€ä½³é¸æ“‡å–æ±ºæ–¼æ•¸æ“šç‰¹æ€§**ï¼Œä½†é€šå¸¸**å±€éƒ¨é›¢ç¾¤é»æ–¹æ³•ï¼ˆLOF, Local Outlier Factorï¼‰æˆ–ä¸€é¡æ”¯æŒå‘é‡æ©Ÿï¼ˆOC-SVM, One-Class SVMï¼‰æœƒè¼ƒåˆé©**ã€‚è®“æˆ‘å€‘ä¾†æ¯”è¼ƒä¸€ä¸‹ä¸‰ç¨®æ–¹æ³•ï¼š  

---

### **ğŸ” 1. é«˜æ–¯æ··åˆæ¨¡å‹ï¼ˆGMM, Gaussian Mixture Modelï¼‰**
ğŸ“Œ **å„ªå‹¢**ï¼š  
âœ”ï¸ èƒ½å¤ é©æ‡‰ä¸åŒçš„æ•¸æ“šåˆ†ä½ˆï¼ˆé©åˆæª¢æ¸¬é€£çºŒè®ŠåŒ–çš„ç•°å¸¸ï¼‰ã€‚  
âœ”ï¸ é©åˆå½±åƒç‰¹å¾µæ¯”è¼ƒé€£çºŒã€å¹³æ»‘çš„ç•°å¸¸ï¼ˆå¦‚é¡è‰²è®ŠåŒ–ã€æ¨¡ç³Šç­‰ï¼‰ã€‚  

ğŸ“Œ **ç¼ºé»**ï¼š  
âŒ å°å±€éƒ¨ç•°å¸¸ï¼ˆå¦‚è£‚ç—•ï¼‰ä¸æ•æ„Ÿï¼Œå› ç‚ºè£‚ç—•é€šå¸¸æ˜¯**å±€éƒ¨ç‰¹å¾µ**ï¼Œä½† GMM åå‘å­¸ç¿’å…¨å±€åˆ†ä½ˆã€‚  
âŒ åœ¨ç•°å¸¸æ•¸æ“šæ¯”ä¾‹è¼ƒä½æ™‚ï¼Œå¯èƒ½ç„¡æ³•æº–ç¢ºå€åˆ†æ­£å¸¸èˆ‡ç•°å¸¸æ¨£æœ¬ã€‚  

**ğŸ“Œ çµè«–**ï¼š  
ğŸ‘‰ **ä¸å¤ªé©åˆ**ç»ç’ƒè£‚ç—•æª¢æ¸¬ï¼Œå› ç‚ºè£‚ç—•é€šå¸¸æ˜¯**å±€éƒ¨ç•°å¸¸**ï¼ŒGMM çš„å…¨å±€å»ºæ¨¡å¯èƒ½ç„¡æ³•å¾ˆå¥½åœ°æª¢æ¸¬åˆ°è£‚ç—•ã€‚

---

### **ğŸ” 2. å±€éƒ¨é›¢ç¾¤å› å­ï¼ˆLOF, Local Outlier Factorï¼‰**
ğŸ“Œ **å„ªå‹¢**ï¼š  
âœ”ï¸ ç‰¹åˆ¥é©åˆ**å±€éƒ¨ç•°å¸¸æª¢æ¸¬**ï¼Œå³è£‚ç—•é€™ç¨®å±€éƒ¨è®ŠåŒ–çš„æƒ…æ³ã€‚  
âœ”ï¸ é€éè¨ˆç®—é„°è¿‘æ¨£æœ¬çš„å¯†åº¦ä¾†åˆ¤æ–·ç•°å¸¸ï¼Œå› æ­¤èƒ½å¤ ç™¼ç¾ç´°å°çš„è£‚ç¸«ã€‚  
âœ”ï¸ å°æ–¼åªæœ‰æ­£å¸¸å½±åƒè¨“ç·´çš„æƒ…æ³ï¼ˆéç›£ç£å­¸ç¿’ï¼‰æ•ˆæœè¼ƒå¥½ã€‚  

ğŸ“Œ **ç¼ºé»**ï¼š  
âŒ è¨ˆç®—é‡è¼ƒå¤§ï¼Œå°æ–¼é«˜ç¶­æ•¸æ“šï¼ˆå¦‚å½±åƒï¼‰å¯èƒ½è¼ƒæ…¢ã€‚  
âŒ éœ€è¦åˆé©çš„ K é„°å±…æ•¸ï¼ˆè¶…åƒæ•¸èª¿æ•´è¼ƒæ•æ„Ÿï¼‰ã€‚  

**ğŸ“Œ çµè«–**ï¼š  
ğŸ‘‰ **é©åˆç»ç’ƒè£‚ç—•æª¢æ¸¬**ï¼Œå› ç‚ºè£‚ç—•é€šå¸¸æ˜¯å±€éƒ¨ç•°å¸¸ï¼Œè€Œ LOF èƒ½æœ‰æ•ˆæ•æ‰é€™äº›ç•°å¸¸é»ã€‚

---

### **ğŸ” 3. ä¸€é¡æ”¯æŒå‘é‡æ©Ÿï¼ˆOC-SVM, One-Class SVMï¼‰**
ğŸ“Œ **å„ªå‹¢**ï¼š  
âœ”ï¸ åªéœ€**æ­£å¸¸æ¨£æœ¬**è¨“ç·´ï¼Œèƒ½å­¸ç¿’æ­£å¸¸å½±åƒçš„ç‰¹å¾µåˆ†ä½ˆã€‚  
âœ”ï¸ èƒ½å¤ è™•ç†é«˜ç¶­æ•¸æ“šï¼Œå¦‚å½±åƒç‰¹å¾µï¼ˆä½†é€šå¸¸éœ€å…ˆé™ç¶­ï¼‰ã€‚  
âœ”ï¸ ç•°å¸¸æª¢æ¸¬æ•ˆæœé€šå¸¸æ¯” GMM ç©©å®šï¼Œç‰¹åˆ¥æ˜¯åœ¨å½±åƒé ˜åŸŸã€‚  

ğŸ“Œ **ç¼ºé»**ï¼š  
âŒ è¨“ç·´æ™‚é–“è¼ƒé•·ï¼Œå°¤å…¶åœ¨æ•¸æ“šè¼ƒå¤šæ™‚ã€‚  
âŒ é«˜ç¶­ç‰¹å¾µå¯èƒ½æœƒå½±éŸ¿åˆ†é¡é‚Šç•Œï¼Œéœ€é©ç•¶é™ç¶­ï¼ˆå¦‚ PCAã€Autoencoderï¼‰ã€‚  

**ğŸ“Œ çµè«–**ï¼š  
ğŸ‘‰ **é©åˆç»ç’ƒè£‚ç—•æª¢æ¸¬**ï¼Œä½†ç›¸æ¯” LOFï¼ŒOC-SVM åœ¨ç´°å°å±€éƒ¨ç•°å¸¸æª¢æ¸¬ä¸Šå¯èƒ½ç¨éœè‰²ã€‚

---

## **ğŸ’¡ çµè«–ï¼šå“ªå€‹æ–¹æ³•æœ€é©åˆç»ç’ƒç“¶è£‚ç—•æª¢æ¸¬ï¼Ÿ**
âœ… **æœ€æ¨è–¦**ï¼š**LOFï¼ˆå±€éƒ¨é›¢ç¾¤å› å­ï¼‰** â€“ èƒ½æœ‰æ•ˆç™¼ç¾è£‚ç—•é€™é¡å±€éƒ¨ç•°å¸¸é»ã€‚  
ğŸ”¹ å¦‚æœæ•¸æ“šè¼ƒå°ï¼Œ**OC-SVM ä¹Ÿæ˜¯å¯è¡Œé¸æ“‡**ï¼Œä½†å°è£‚ç—•é€™é¡å±€éƒ¨ç‰¹å¾µçš„æ•æ„Ÿåº¦å¯èƒ½ä¸å¦‚ LOFã€‚  
ğŸš« **ä¸æ¨è–¦ GMM**ï¼Œå› ç‚ºå®ƒå°æ–¼å±€éƒ¨ç•°å¸¸ä¸å¤ æ•æ„Ÿï¼Œå¯èƒ½é›£ä»¥æº–ç¢ºè­˜åˆ¥è£‚ç—•ã€‚  

---

## **ğŸ“Œ ä½ å¯ä»¥é€™æ¨£åš**
1ï¸âƒ£ **å…ˆç”¨ OpenCV åšå½±åƒé è™•ç†**ï¼ˆå¦‚é‚Šç·£æª¢æ¸¬ã€è¼ªå»“å¼·åŒ–ï¼‰ã€‚  
2ï¸âƒ£ **æå–å½±åƒç‰¹å¾µ**ï¼ˆå¦‚ HOGã€LBPï¼Œæˆ–ç”¨ CNN èƒå–ç‰¹å¾µï¼‰ã€‚  
3ï¸âƒ£ **ä½¿ç”¨ LOF æˆ– OC-SVM é€²è¡Œç•°å¸¸æª¢æ¸¬**ã€‚  
4ï¸âƒ£ **å¯è¦–åŒ–ç•°å¸¸çµæœ**ï¼Œä¸¦èª¿æ•´è¶…åƒæ•¸ä»¥æå‡æº–ç¢ºåº¦ã€‚  

---

å­¸ç¿’æ–¹æ³•:å¯ä»¥åˆ†ç‚º **å‚³çµ±æ©Ÿå™¨å­¸ç¿’æ–¹æ³•ï¼ˆå¦‚ LOFã€OC-SVMï¼‰** å’Œ **æ·±åº¦å­¸ç¿’æ–¹æ³•ï¼ˆå¦‚ Autoencoder, GANï¼‰** ä¾†åšç»ç’ƒç“¶è£‚ç—•æª¢æ¸¬ã€‚æä¾›å…©ç¨®å®Œæ•´çš„ **æ­¥é©Ÿèˆ‡ç¨‹å¼ç¯„ä¾‹**ã€‚

---

# **ğŸŸ¢ 1. å‚³çµ±æ©Ÿå™¨å­¸ç¿’æ–¹æ³•**
å‚³çµ±æ–¹æ³•ä¸»è¦ä¾é **å½±åƒç‰¹å¾µèƒå–**ï¼ˆå¦‚ HOGã€LBPï¼‰ä¾†é€²è¡Œç•°å¸¸æª¢æ¸¬ï¼Œç„¶å¾Œä½¿ç”¨ **LOF æˆ– OC-SVM** ä¾†å­¸ç¿’æ­£å¸¸æ¨£æœ¬åˆ†ä½ˆï¼Œåµæ¸¬ç•°å¸¸ã€‚

## **ğŸ”¹ æ–¹æ³•é¸æ“‡**
âœ… **LOFï¼ˆå±€éƒ¨é›¢ç¾¤å› å­ï¼‰** â†’ é©åˆå±€éƒ¨ç•°å¸¸ï¼Œå¦‚è£‚ç—•ã€‚  
âœ… **OC-SVMï¼ˆä¸€é¡ SVMï¼‰** â†’ é©åˆæ•´é«”ç•°å¸¸åµæ¸¬ï¼Œä½†å¯èƒ½å°è£‚ç—•ä¸å¤ æ•æ„Ÿã€‚  
ğŸš« **ä¸é©åˆ GMM**ï¼Œå› ç‚ºè£‚ç—•æ˜¯å±€éƒ¨ç•°å¸¸ï¼ŒGMM åå‘å­¸ç¿’æ•´é«”åˆ†ä½ˆã€‚

---

## **ğŸ“Œ æ­¥é©Ÿ**
1ï¸âƒ£ è®€å–å½±åƒ  
2ï¸âƒ£ å½±åƒé è™•ç†ï¼ˆç°éšã€éŠ³åŒ–ã€é‚Šç·£å¼·åŒ–ç­‰ï¼‰  
3ï¸âƒ£ èƒå–ç‰¹å¾µï¼ˆHOG, LBPï¼‰  
4ï¸âƒ£ è¨“ç·´ç•°å¸¸æª¢æ¸¬æ¨¡å‹ï¼ˆLOF / OC-SVMï¼‰  
5ï¸âƒ£ æ¸¬è©¦æ–°å½±åƒä¸¦æ¨™è¨˜ç•°å¸¸ä½ç½®  

---

## **ğŸ”¹ Python ç¨‹å¼ï¼ˆä½¿ç”¨ LOFï¼‰**

```python
import cv2
import numpy as np
from skimage.feature import local_binary_pattern
from sklearn.neighbors import LocalOutlierFactor
import glob
import os

# åƒæ•¸è¨­å®š
RADIUS = 3  # LBP åŠå¾‘
N_POINTS = 8 * RADIUS  # LBP é„°å±…é»
THRESHOLD = -1.5  # LOF é–¾å€¼ï¼ˆä½æ–¼æ­¤å€¼ç‚ºç•°å¸¸ï¼‰

# è®€å–æ‰€æœ‰æ­£å¸¸å½±åƒä¾†è¨“ç·´ LOF
image_paths = glob.glob("normal_images/*.jpg")
feature_list = []

for img_path in image_paths:
    img = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)
    img = cv2.resize(img, (128, 128))  # èª¿æ•´å¤§å°
    lbp = local_binary_pattern(img, N_POINTS, RADIUS, method="uniform")  # èƒå– LBP ç‰¹å¾µ
    hist, _ = np.histogram(lbp.ravel(), bins=np.arange(0, N_POINTS + 3), density=True)
    feature_list.append(hist)

# è¨“ç·´ LOF æ¨¡å‹
lof = LocalOutlierFactor(n_neighbors=20, novelty=True)
lof.fit(feature_list)

# æ¸¬è©¦ç•°å¸¸å½±åƒ
test_img = cv2.imread("test_image.jpg", cv2.IMREAD_GRAYSCALE)
test_img = cv2.resize(test_img, (128, 128))
lbp = local_binary_pattern(test_img, N_POINTS, RADIUS, method="uniform")
hist, _ = np.histogram(lbp.ravel(), bins=np.arange(0, N_POINTS + 3), density=True)

# é æ¸¬ç•°å¸¸åº¦
score = lof.decision_function([hist])
print(f"ç•°å¸¸åˆ†æ•¸: {score}")

# å¦‚æœç•°å¸¸åˆ†æ•¸ä½æ–¼é–¾å€¼ï¼Œå‰‡åˆ¤å®šç‚ºç•°å¸¸
if score < THRESHOLD:
    print("åµæ¸¬åˆ°è£‚ç—•ï¼")
else:
    print("å½±åƒæ­£å¸¸")
```

---

# **ğŸ”µ 2. æ·±åº¦å­¸ç¿’æ–¹æ³•**
æ·±åº¦å­¸ç¿’æ–¹æ³•ä¸ä¾è³´æ‰‹å‹•ç‰¹å¾µï¼Œè€Œæ˜¯ç”¨ **CNN è‡ªå‹•å­¸ç¿’ç‰¹å¾µ**ï¼Œç„¶å¾Œä½¿ç”¨ **Autoencoder æˆ– GAN ä¾†æª¢æ¸¬ç•°å¸¸**ã€‚

## **ğŸ”¹ æ–¹æ³•é¸æ“‡**
âœ… **Autoencoderï¼ˆè‡ªç·¨ç¢¼å™¨ï¼‰** â†’ é©åˆå­¸ç¿’æ­£å¸¸æ¨£æœ¬ï¼Œç•°å¸¸æ¨£æœ¬é‡å»ºèª¤å·®å¤§æ™‚åˆ¤ç‚ºç•°å¸¸ã€‚  
âœ… **GANï¼ˆç”Ÿæˆå°æŠ—ç¶²è·¯ï¼‰** â†’ ä½¿ç”¨æ­£å¸¸å½±åƒç”Ÿæˆå°æ‡‰çš„ç•°å¸¸ç‰ˆæœ¬ï¼Œç„¶å¾Œæ¯”è¼ƒå·®ç•°ã€‚  

---

## **ğŸ“Œ Autoencoder æ–¹æ³•**
1ï¸âƒ£ å»ºç«‹ **CNN Autoencoder** æ¨¡å‹  
2ï¸âƒ£ åªç”¨**æ­£å¸¸å½±åƒ**è¨“ç·´  
3ï¸âƒ£ æ¸¬è©¦å½±åƒï¼Œè¨ˆç®—é‡å»ºèª¤å·®  
4ï¸âƒ£ é‡å»ºèª¤å·®å¤§æ–¼é–¾å€¼æ™‚ï¼Œåˆ¤å®šç‚ºç•°å¸¸  

---

## **ğŸ”¹ Python ç¨‹å¼ï¼ˆAutoencoderï¼‰**
```python
import tensorflow as tf
from tensorflow.keras.models import Model
from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, UpSampling2D
import numpy as np
import cv2
import glob

# å»ºç«‹ Autoencoder æ¨¡å‹
input_img = Input(shape=(128, 128, 1))

# Encoder
x = Conv2D(32, (3, 3), activation='relu', padding='same')(input_img)
x = MaxPooling2D((2, 2), padding='same')(x)
x = Conv2D(16, (3, 3), activation='relu', padding='same')(x)
x = MaxPooling2D((2, 2), padding='same')(x)

# Decoder
x = Conv2D(16, (3, 3), activation='relu', padding='same')(x)
x = UpSampling2D((2, 2))(x)
x = Conv2D(32, (3, 3), activation='relu', padding='same')(x)
x = UpSampling2D((2, 2))(x)
decoded = Conv2D(1, (3, 3), activation='sigmoid', padding='same')(x)

autoencoder = Model(input_img, decoded)
autoencoder.compile(optimizer='adam', loss='mse')

# è®€å–æ­£å¸¸å½±åƒä¸¦è¨“ç·´
image_paths = glob.glob("normal_images/*.jpg")
train_data = []

for img_path in image_paths:
    img = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)
    img = cv2.resize(img, (128, 128))
    train_data.append(img / 255.0)  # æ­£è¦åŒ–

train_data = np.array(train_data).reshape(-1, 128, 128, 1)

# è¨“ç·´ Autoencoder
autoencoder.fit(train_data, train_data, epochs=50, batch_size=16, shuffle=True)

# æ¸¬è©¦ç•°å¸¸å½±åƒ
test_img = cv2.imread("test_image.jpg", cv2.IMREAD_GRAYSCALE)
test_img = cv2.resize(test_img, (128, 128)) / 255.0
test_img = np.expand_dims(test_img, axis=(0, -1))

# é‡å»ºå½±åƒ
reconstructed = autoencoder.predict(test_img)

# è¨ˆç®—é‡å»ºèª¤å·®
mse = np.mean((test_img - reconstructed) ** 2)
print(f"é‡å»ºèª¤å·®: {mse}")

# è¨­å®šé–¾å€¼åˆ¤æ–·ç•°å¸¸
THRESHOLD = 0.02
if mse > THRESHOLD:
    print("åµæ¸¬åˆ°è£‚ç—•ï¼")
else:
    print("å½±åƒæ­£å¸¸")
```

---

# **ğŸ“Œ ç¸½çµ**
| æ–¹æ³• | é©åˆè£‚ç—•æª¢æ¸¬ï¼Ÿ | ä¸»è¦å„ªé» | ä¸»è¦ç¼ºé» |
|------|----------------|----------|----------|
| **LOFï¼ˆå‚³çµ±æ©Ÿå™¨å­¸ç¿’ï¼‰** | âœ… æ˜¯ | æ˜“æ–¼è¨“ç·´ï¼Œå°å±€éƒ¨ç•°å¸¸æ•æ„Ÿ | è¨ˆç®—é‡è¼ƒå¤§ |
| **OC-SVMï¼ˆå‚³çµ±æ©Ÿå™¨å­¸ç¿’ï¼‰** | âœ… å¯èƒ½ | åªéœ€æ­£å¸¸æ¨£æœ¬è¨“ç·´ | å¯èƒ½ä¸å¤ éˆæ• |
| **Autoencoderï¼ˆæ·±åº¦å­¸ç¿’ï¼‰** | âœ… æ˜¯ | è‡ªå‹•å­¸ç¿’ç‰¹å¾µï¼Œé©åˆç•°å¸¸æª¢æ¸¬ | éœ€è¼ƒå¤šæ­£å¸¸å½±åƒ |
| **GANï¼ˆæ·±åº¦å­¸ç¿’ï¼‰** | âœ… å¯èƒ½ | èƒ½åˆæˆç•°å¸¸æ¨£æœ¬ï¼Œå°æ¯”å­¸ç¿’ | è¨“ç·´è¼ƒè¤‡é›œ |

---
ğŸ’¡ **å»ºè­°**
- æ¨£æœ¬å°‘æ™‚ï¼š**LOF / OC-SVM**
- æ¨£æœ¬å¤šæ™‚ï¼š**Autoencoder**
- éœ€è¦ç”Ÿæˆç•°å¸¸æ¨£æœ¬ï¼š**GAN**

---

å®Œæ•´çš„ **Autoencoder** è¨“ç·´èˆ‡æ¨¡å‹å­˜å–ç¯„ä¾‹ï¼š  

### **æ­¥é©Ÿ 1ï¼šè¨“ç·´ Autoencoder ä¸¦å­˜æª”**
```python
import tensorflow as tf
from tensorflow.keras.models import Model
from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, UpSampling2D
import numpy as np
import cv2
import os
from tensorflow.keras.models import load_model

# æ§‹å»º Autoencoder æ¨¡å‹
def build_autoencoder(input_shape):
    input_img = Input(shape=input_shape)
    
    # Encoder
    x = Conv2D(32, (3, 3), activation='relu', padding='same')(input_img)
    x = MaxPooling2D((2, 2), padding='same')(x)
    x = Conv2D(64, (3, 3), activation='relu', padding='same')(x)
    x = MaxPooling2D((2, 2), padding='same')(x)
    
    # Decoder
    x = Conv2D(64, (3, 3), activation='relu', padding='same')(x)
    x = UpSampling2D((2, 2))(x)
    x = Conv2D(32, (3, 3), activation='relu', padding='same')(x)
    x = UpSampling2D((2, 2))(x)
    decoded = Conv2D(1, (3, 3), activation='sigmoid', padding='same')(x)
    
    autoencoder = Model(input_img, decoded)
    autoencoder.compile(optimizer='adam', loss='mse')
    
    return autoencoder

# è®€å–è¨“ç·´æ•¸æ“šï¼ˆå‡è¨­æ˜¯æ­£å¸¸ç»ç’ƒç“¶å½±åƒï¼‰
def load_training_data(data_path, img_size=(128, 128)):
    images = []
    for filename in os.listdir(data_path):
        img = cv2.imread(os.path.join(data_path, filename), cv2.IMREAD_GRAYSCALE)
        img = cv2.resize(img, img_size)
        img = img.astype('float32') / 255.0  # æ­£è¦åŒ–
        images.append(img)
    return np.array(images).reshape(-1, img_size[0], img_size[1], 1)

# è¨“ç·´æ¨¡å‹
data_path = "train_images/"  # éœ€æ›¿æ›ç‚ºå¯¦éš›çš„æ­£å¸¸æ¨£æœ¬è³‡æ–™å¤¾
train_images = load_training_data(data_path)

input_shape = (128, 128, 1)
autoencoder = build_autoencoder(input_shape)

autoencoder.fit(train_images, train_images, epochs=50, batch_size=16, shuffle=True)

# å„²å­˜æ¨¡å‹
autoencoder.save("glass_bottle_autoencoder.h5")
print("æ¨¡å‹å·²å„²å­˜")
```

---

### **æ­¥é©Ÿ 2ï¼šè¼‰å…¥æ¨¡å‹ä¸¦æª¢æ¸¬è£‚ç—•**
```python
# è¼‰å…¥å·²è¨“ç·´çš„æ¨¡å‹
autoencoder = load_model("glass_bottle_autoencoder.h5")

# è®€å–æ–°åœ–ç‰‡ä¸¦æª¢æ¸¬ç•°å¸¸
def detect_anomaly(image_path, threshold=0.05):
    img = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)
    img = cv2.resize(img, (128, 128))
    img = img.astype('float32') / 255.0
    img = img.reshape(1, 128, 128, 1)

    # é€²è¡Œ Autoencoder é æ¸¬
    reconstructed = autoencoder.predict(img)

    # è¨ˆç®—ç•°å¸¸å€åŸŸ
    error_map = np.abs(img - reconstructed)
    error_score = np.mean(error_map)

    if error_score > threshold:
        print(f"ç•°å¸¸åµæ¸¬: ç•°å¸¸ (èª¤å·®: {error_score:.4f})")
    else:
        print(f"ç•°å¸¸åµæ¸¬: æ­£å¸¸ (èª¤å·®: {error_score:.4f})")

    return error_map

# æ¸¬è©¦ç•°å¸¸æª¢æ¸¬
image_path = "test_images/cracked_bottle.jpg"  # éœ€æ›¿æ›ç‚ºå¯¦éš›æ¸¬è©¦åœ–ç‰‡
error_map = detect_anomaly(image_path)
cv2.imshow("Error Map", error_map[0])
cv2.waitKey(0)
cv2.destroyAllWindows()
```

é€™æ¨£å°±å¯ä»¥ï¼š
1. è¨“ç·´ **Autoencoder**ï¼Œåªéœ€æ­£å¸¸çš„ç»ç’ƒç“¶åœ–ç‰‡
2. å­˜å„²ä¸¦è¼‰å…¥æ¨¡å‹
3. æª¢æ¸¬ç•°å¸¸ï¼Œä¸¦è¨ˆç®—èª¤å·®ä¾†åˆ¤æ–·è£‚ç—•

å¯ä»¥èª¿æ•´ `threshold=0.05` ä¾†æ”¹è®Šç•°å¸¸åˆ¤å®šçš„æ•æ„Ÿåº¦ã€‚  
é€™æ¨£çš„æ–¹æ³•é©åˆå°æ¨£æœ¬çš„ç•°å¸¸æª¢æ¸¬ï¼Œä¸¦ä¸”èƒ½é©æ‡‰ä¸åŒçš„ç’°å¢ƒã€‚  

å®Œæ•´çš„ç¨‹å¼: [autoencoder.py]
